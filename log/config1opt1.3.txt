
CONFIG 1 OPT 1.3
training_args = TrainingArguments(
    output_dir=output_dir,
    eval_strategy="epoch",
    learning_rate=1e-5,
    lr_scheduler_type= "cosine",
    warmup_ratio= 0.1,
    weight_decay=0.1,
    per_device_train_batch_size=16,
    num_train_epochs= 3,
    logging_steps=1,
    logging_dir="/home/ubuntu/projects/LLMRSResearch/log",
    logging_first_step=True

)
{'loss': 3.0502, 'grad_norm': 12.716082572937012, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.12}                                               
{'loss': 2.925, 'grad_norm': 8.618382453918457, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.25}                                                  
{'loss': 2.9295, 'grad_norm': 9.884743690490723, 'learning_rate': 1e-05, 'epoch': 0.38}                                                                 
{'loss': 2.9509, 'grad_norm': 12.322990417480469, 'learning_rate': 9.944154131125643e-06, 'epoch': 0.5}                                                 
{'loss': 3.054, 'grad_norm': 10.978641510009766, 'learning_rate': 9.777864028930705e-06, 'epoch': 0.62}                                                 
{'loss': 2.7639, 'grad_norm': 7.030930042266846, 'learning_rate': 9.504844339512096e-06, 'epoch': 0.75}                                                 
{'loss': 2.854, 'grad_norm': 8.428085327148438, 'learning_rate': 9.131193871579975e-06, 'epoch': 0.88}                                                  
{'loss': 2.9899, 'grad_norm': 8.186141967773438, 'learning_rate': 8.665259359149132e-06, 'epoch': 1.0}                                                  
{'eval_loss': 2.9055352210998535, 'eval_runtime': 0.6978, 'eval_samples_per_second': 44.426, 'eval_steps_per_second': 5.732, 'epoch': 1.0}              
{'loss': 2.5509, 'grad_norm': 7.200104236602783, 'learning_rate': 8.117449009293668e-06, 'epoch': 1.12}                                                 
{'loss': 2.6703, 'grad_norm': 7.508694171905518, 'learning_rate': 7.500000000000001e-06, 'epoch': 1.25}                                                 
{'loss': 2.2604, 'grad_norm': 6.933730125427246, 'learning_rate': 6.8267051218319766e-06, 'epoch': 1.38}                                                
{'loss': 2.3445, 'grad_norm': 6.717233657836914, 'learning_rate': 6.112604669781572e-06, 'epoch': 1.5}                                                  
{'loss': 2.2431, 'grad_norm': 6.396839141845703, 'learning_rate': 5.373650467932122e-06, 'epoch': 1.62}                                                 
{'loss': 2.3617, 'grad_norm': 7.255385875701904, 'learning_rate': 4.626349532067879e-06, 'epoch': 1.75}                                                 
{'loss': 2.5298, 'grad_norm': 7.589850902557373, 'learning_rate': 3.887395330218429e-06, 'epoch': 1.88}                                                 
{'loss': 2.3605, 'grad_norm': 8.866549491882324, 'learning_rate': 3.173294878168025e-06, 'epoch': 2.0}                                                  
{'eval_loss': 2.7968971729278564, 'eval_runtime': 0.6993, 'eval_samples_per_second': 44.329, 'eval_steps_per_second': 5.72, 'epoch': 2.0}               
{'loss': 2.1781, 'grad_norm': 6.953734874725342, 'learning_rate': 2.5000000000000015e-06, 'epoch': 2.12}                                                
{'loss': 2.0615, 'grad_norm': 6.229968070983887, 'learning_rate': 1.8825509907063328e-06, 'epoch': 2.25}                                                
{'loss': 2.3007, 'grad_norm': 6.18592643737793, 'learning_rate': 1.3347406408508695e-06, 'epoch': 2.38}                                                 
{'loss': 2.3766, 'grad_norm': 7.147775650024414, 'learning_rate': 8.688061284200266e-07, 'epoch': 2.5}                                                  
{'loss': 2.1814, 'grad_norm': 6.796684741973877, 'learning_rate': 4.951556604879049e-07, 'epoch': 2.62}                                                 
{'loss': 2.1361, 'grad_norm': 6.736194133758545, 'learning_rate': 2.2213597106929608e-07, 'epoch': 2.75}                                                
{'loss': 2.0624, 'grad_norm': 6.683173179626465, 'learning_rate': 5.584586887435739e-08, 'epoch': 2.88}                                                 
{'loss': 1.9953, 'grad_norm': 6.4098734855651855, 'learning_rate': 0.0, 'epoch': 3.0}                                                                   
{'eval_loss': 2.779473066329956, 'eval_runtime': 0.6972, 'eval_samples_per_second': 44.462, 'eval_steps_per_second': 5.737, 'epoch': 3.0}               
{'train_runtime': 100.5764, 'train_samples_per_second': 3.699, 'train_steps_per_second': 0.239, 'train_loss': 2.5054409752289453, 'epoch': 3.0} 