{
    "run_name": "run_14_r16_alpha32_lr5e-05_optpaged_adamw_8bit_ep3",
    "r": 16,
    "lora_alpha": 32,
    "optim": "paged_adamw_8bit",
    "learning_rate": 5e-05,
    "lr_scheduler": "cosine",
    "weight_decay": 0.01,
    "num_train_epochs": 3,
    "train_log": [
        {
            "loss": 3.4217,
            "grad_norm": 1.8573086261749268,
            "learning_rate": 4.972856671504576e-05,
            "epoch": 0.14084507042253522,
            "step": 10
        },
        {
            "loss": 3.2613,
            "grad_norm": 1.7805665731430054,
            "learning_rate": 4.892016094243753e-05,
            "epoch": 0.28169014084507044,
            "step": 20
        },
        {
            "loss": 3.2665,
            "grad_norm": 2.328336238861084,
            "learning_rate": 4.75923369409301e-05,
            "epoch": 0.4225352112676056,
            "step": 30
        },
        {
            "loss": 2.768,
            "grad_norm": 2.131662607192993,
            "learning_rate": 4.57739279609691e-05,
            "epoch": 0.5633802816901409,
            "step": 40
        },
        {
            "loss": 2.7523,
            "grad_norm": 3.2538490295410156,
            "learning_rate": 4.350442014038021e-05,
            "epoch": 0.704225352112676,
            "step": 50
        },
        {
            "loss": 2.7747,
            "grad_norm": 3.6278128623962402,
            "learning_rate": 4.083309507620118e-05,
            "epoch": 0.8450704225352113,
            "step": 60
        },
        {
            "loss": 2.8988,
            "grad_norm": 3.7707245349884033,
            "learning_rate": 3.7817959691420056e-05,
            "epoch": 0.9859154929577465,
            "step": 70
        },
        {
            "loss": 2.6884,
            "grad_norm": 4.76343297958374,
            "learning_rate": 3.4524486634202685e-05,
            "epoch": 1.1267605633802817,
            "step": 80
        },
        {
            "loss": 2.2846,
            "grad_norm": 4.9581170082092285,
            "learning_rate": 3.102419256141536e-05,
            "epoch": 1.267605633802817,
            "step": 90
        },
        {
            "loss": 2.2468,
            "grad_norm": 5.520167350769043,
            "learning_rate": 2.7393085178536686e-05,
            "epoch": 1.408450704225352,
            "step": 100
        },
        {
            "loss": 2.2332,
            "grad_norm": 5.250093936920166,
            "learning_rate": 2.3710012757963175e-05,
            "epoch": 1.5492957746478875,
            "step": 110
        },
        {
            "loss": 2.172,
            "grad_norm": 6.66067361831665,
            "learning_rate": 2.0054951975362067e-05,
            "epoch": 1.6901408450704225,
            "step": 120
        },
        {
            "loss": 1.9165,
            "grad_norm": 5.676559925079346,
            "learning_rate": 1.650727124312768e-05,
            "epoch": 1.8309859154929577,
            "step": 130
        },
        {
            "loss": 2.0641,
            "grad_norm": 7.116944313049316,
            "learning_rate": 1.3144007252069552e-05,
            "epoch": 1.971830985915493,
            "step": 140
        },
        {
            "loss": 2.0234,
            "grad_norm": 6.95892858505249,
            "learning_rate": 1.0038192145648567e-05,
            "epoch": 2.112676056338028,
            "step": 150
        },
        {
            "loss": 1.8327,
            "grad_norm": 8.021013259887695,
            "learning_rate": 7.257267651608446e-06,
            "epoch": 2.2535211267605635,
            "step": 160
        },
        {
            "loss": 1.7073,
            "grad_norm": 8.390650749206543,
            "learning_rate": 4.861620607599346e-06,
            "epoch": 2.3943661971830985,
            "step": 170
        },
        {
            "loss": 1.5874,
            "grad_norm": 6.539576530456543,
            "learning_rate": 2.9032716813609723e-06,
            "epoch": 2.535211267605634,
            "step": 180
        },
        {
            "loss": 1.6797,
            "grad_norm": 6.010012149810791,
            "learning_rate": 1.4247457594641662e-06,
            "epoch": 2.676056338028169,
            "step": 190
        },
        {
            "loss": 1.6936,
            "grad_norm": 7.912099838256836,
            "learning_rate": 4.581485337385588e-07,
            "epoch": 2.816901408450704,
            "step": 200
        },
        {
            "loss": 1.5685,
            "grad_norm": 5.963346481323242,
            "learning_rate": 2.44693370006599e-08,
            "epoch": 2.9577464788732395,
            "step": 210
        },
        {
            "train_runtime": 1860.1553,
            "train_samples_per_second": 1.83,
            "train_steps_per_second": 0.115,
            "total_flos": 7.896359453589504e+16,
            "train_loss": 2.3205243321091915,
            "epoch": 3.0,
            "step": 213
        },
        {
            "eval_loss": 2.36537504196167,
            "eval_runtime": 52.239,
            "eval_samples_per_second": 5.437,
            "eval_steps_per_second": 0.689,
            "epoch": 3.0,
            "step": 213
        }
    ],
    "perplexity": 10.64803152737829
}