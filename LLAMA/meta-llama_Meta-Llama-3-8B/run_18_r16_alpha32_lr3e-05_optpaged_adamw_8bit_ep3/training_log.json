{
    "run_name": "run_18_r16_alpha32_lr3e-05_optpaged_adamw_8bit_ep3",
    "r": 16,
    "lora_alpha": 32,
    "optim": "paged_adamw_8bit",
    "learning_rate": 3e-05,
    "lr_scheduler": "cosine",
    "weight_decay": 0.01,
    "num_train_epochs": 3,
    "train_log": [
        {
            "loss": 3.4554,
            "grad_norm": 1.6738746166229248,
            "learning_rate": 2.983714002902746e-05,
            "epoch": 0.14084507042253522,
            "step": 10
        },
        {
            "loss": 3.3706,
            "grad_norm": 1.4865995645523071,
            "learning_rate": 2.9352096565462518e-05,
            "epoch": 0.28169014084507044,
            "step": 20
        },
        {
            "loss": 3.4446,
            "grad_norm": 2.1506919860839844,
            "learning_rate": 2.8555402164558058e-05,
            "epoch": 0.4225352112676056,
            "step": 30
        },
        {
            "loss": 2.9202,
            "grad_norm": 1.988322138786316,
            "learning_rate": 2.746435677658146e-05,
            "epoch": 0.5633802816901409,
            "step": 40
        },
        {
            "loss": 2.9076,
            "grad_norm": 2.9071238040924072,
            "learning_rate": 2.6102652084228125e-05,
            "epoch": 0.704225352112676,
            "step": 50
        },
        {
            "loss": 2.9571,
            "grad_norm": 2.8253636360168457,
            "learning_rate": 2.4499857045720705e-05,
            "epoch": 0.8450704225352113,
            "step": 60
        },
        {
            "loss": 3.0978,
            "grad_norm": 3.225377321243286,
            "learning_rate": 2.2690775814852032e-05,
            "epoch": 0.9859154929577465,
            "step": 70
        },
        {
            "loss": 2.9865,
            "grad_norm": 3.7148356437683105,
            "learning_rate": 2.071469198052161e-05,
            "epoch": 1.1267605633802817,
            "step": 80
        },
        {
            "loss": 2.6228,
            "grad_norm": 4.051143169403076,
            "learning_rate": 1.8614515536849215e-05,
            "epoch": 1.267605633802817,
            "step": 90
        },
        {
            "loss": 2.5882,
            "grad_norm": 4.450407028198242,
            "learning_rate": 1.6435851107122013e-05,
            "epoch": 1.408450704225352,
            "step": 100
        },
        {
            "loss": 2.5683,
            "grad_norm": 4.141295909881592,
            "learning_rate": 1.4226007654777903e-05,
            "epoch": 1.5492957746478875,
            "step": 110
        },
        {
            "loss": 2.5331,
            "grad_norm": 5.291101932525635,
            "learning_rate": 1.2032971185217241e-05,
            "epoch": 1.6901408450704225,
            "step": 120
        },
        {
            "loss": 2.2756,
            "grad_norm": 4.45143985748291,
            "learning_rate": 9.904362745876609e-06,
            "epoch": 1.8309859154929577,
            "step": 130
        },
        {
            "loss": 2.3981,
            "grad_norm": 5.999342441558838,
            "learning_rate": 7.886404351241731e-06,
            "epoch": 1.971830985915493,
            "step": 140
        },
        {
            "loss": 2.5179,
            "grad_norm": 5.5623273849487305,
            "learning_rate": 6.02291528738914e-06,
            "epoch": 2.112676056338028,
            "step": 150
        },
        {
            "loss": 2.3194,
            "grad_norm": 6.190659046173096,
            "learning_rate": 4.3543605909650676e-06,
            "epoch": 2.2535211267605635,
            "step": 160
        },
        {
            "loss": 2.2444,
            "grad_norm": 6.32301664352417,
            "learning_rate": 2.9169723645596075e-06,
            "epoch": 2.3943661971830985,
            "step": 170
        },
        {
            "loss": 2.111,
            "grad_norm": 5.443158149719238,
            "learning_rate": 1.7419630088165832e-06,
            "epoch": 2.535211267605634,
            "step": 180
        },
        {
            "loss": 2.2326,
            "grad_norm": 4.662041187286377,
            "learning_rate": 8.548474556784997e-07,
            "epoch": 2.676056338028169,
            "step": 190
        },
        {
            "loss": 2.2381,
            "grad_norm": 6.3005852699279785,
            "learning_rate": 2.748891202431353e-07,
            "epoch": 2.816901408450704,
            "step": 200
        },
        {
            "loss": 2.2194,
            "grad_norm": 4.881643772125244,
            "learning_rate": 1.4681602200395938e-08,
            "epoch": 2.9577464788732395,
            "step": 210
        },
        {
            "train_runtime": 1859.9044,
            "train_samples_per_second": 1.831,
            "train_steps_per_second": 0.115,
            "total_flos": 7.896359453589504e+16,
            "train_loss": 2.663930185523951,
            "epoch": 3.0,
            "step": 213
        },
        {
            "eval_loss": 2.613229274749756,
            "eval_runtime": 52.1762,
            "eval_samples_per_second": 5.443,
            "eval_steps_per_second": 0.69,
            "epoch": 3.0,
            "step": 213
        }
    ],
    "perplexity": 13.643036906670844
}