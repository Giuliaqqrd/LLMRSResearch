{
    "run_name": "run_5_facebookopt1.3_lr5e-05_schedlinear_wd0.001_epochs5",
    "learning_rate": 5e-05,
    "lr_scheduler": "linear",
    "weight_decay": 0.001,
    "num_train_epochs": 5,
    "train_log": [
        {
            "loss": 3.4486,
            "grad_norm": 12.579630851745605,
            "learning_rate": 2.777777777777778e-06,
            "epoch": 0.027777777777777776,
            "step": 1
        },
        {
            "loss": 3.6385,
            "grad_norm": 10.81629753112793,
            "learning_rate": 2.777777777777778e-05,
            "epoch": 0.2777777777777778,
            "step": 10
        },
        {
            "loss": 3.2264,
            "grad_norm": 9.572066307067871,
            "learning_rate": 4.938271604938271e-05,
            "epoch": 0.5555555555555556,
            "step": 20
        },
        {
            "loss": 2.7763,
            "grad_norm": 10.252462387084961,
            "learning_rate": 4.62962962962963e-05,
            "epoch": 0.8333333333333334,
            "step": 30
        },
        {
            "eval_loss": 2.3366429805755615,
            "eval_runtime": 3.4999,
            "eval_samples_per_second": 81.144,
            "eval_steps_per_second": 10.286,
            "epoch": 1.0,
            "step": 36
        },
        {
            "loss": 2.1938,
            "grad_norm": 9.638155937194824,
            "learning_rate": 4.3209876543209875e-05,
            "epoch": 1.1111111111111112,
            "step": 40
        },
        {
            "loss": 1.4548,
            "grad_norm": 6.574174404144287,
            "learning_rate": 4.012345679012346e-05,
            "epoch": 1.3888888888888888,
            "step": 50
        },
        {
            "loss": 1.3858,
            "grad_norm": 7.747543811798096,
            "learning_rate": 3.7037037037037037e-05,
            "epoch": 1.6666666666666665,
            "step": 60
        },
        {
            "loss": 1.2331,
            "grad_norm": 6.223819255828857,
            "learning_rate": 3.395061728395062e-05,
            "epoch": 1.9444444444444444,
            "step": 70
        },
        {
            "eval_loss": 1.8079524040222168,
            "eval_runtime": 3.5059,
            "eval_samples_per_second": 81.007,
            "eval_steps_per_second": 10.269,
            "epoch": 2.0,
            "step": 72
        },
        {
            "loss": 0.8119,
            "grad_norm": 7.722801208496094,
            "learning_rate": 3.08641975308642e-05,
            "epoch": 2.2222222222222223,
            "step": 80
        },
        {
            "loss": 0.6939,
            "grad_norm": 7.108621120452881,
            "learning_rate": 2.777777777777778e-05,
            "epoch": 2.5,
            "step": 90
        },
        {
            "loss": 0.6539,
            "grad_norm": 5.100222587585449,
            "learning_rate": 2.4691358024691357e-05,
            "epoch": 2.7777777777777777,
            "step": 100
        },
        {
            "eval_loss": 1.6830066442489624,
            "eval_runtime": 3.5069,
            "eval_samples_per_second": 80.983,
            "eval_steps_per_second": 10.265,
            "epoch": 3.0,
            "step": 108
        },
        {
            "loss": 0.6758,
            "grad_norm": 4.340209484100342,
            "learning_rate": 2.1604938271604937e-05,
            "epoch": 3.0555555555555554,
            "step": 110
        },
        {
            "loss": 0.4415,
            "grad_norm": 7.271848678588867,
            "learning_rate": 1.8518518518518518e-05,
            "epoch": 3.3333333333333335,
            "step": 120
        },
        {
            "loss": 0.4346,
            "grad_norm": 5.4427056312561035,
            "learning_rate": 1.54320987654321e-05,
            "epoch": 3.611111111111111,
            "step": 130
        },
        {
            "loss": 0.4105,
            "grad_norm": 5.243268966674805,
            "learning_rate": 1.2345679012345678e-05,
            "epoch": 3.888888888888889,
            "step": 140
        },
        {
            "eval_loss": 1.6613813638687134,
            "eval_runtime": 3.5051,
            "eval_samples_per_second": 81.025,
            "eval_steps_per_second": 10.271,
            "epoch": 4.0,
            "step": 144
        },
        {
            "loss": 0.3325,
            "grad_norm": 3.4224867820739746,
            "learning_rate": 9.259259259259259e-06,
            "epoch": 4.166666666666667,
            "step": 150
        },
        {
            "loss": 0.295,
            "grad_norm": 2.8730902671813965,
            "learning_rate": 6.172839506172839e-06,
            "epoch": 4.444444444444445,
            "step": 160
        },
        {
            "loss": 0.3077,
            "grad_norm": 3.7779150009155273,
            "learning_rate": 3.0864197530864196e-06,
            "epoch": 4.722222222222222,
            "step": 170
        },
        {
            "loss": 0.3659,
            "grad_norm": 6.497217655181885,
            "learning_rate": 0.0,
            "epoch": 5.0,
            "step": 180
        },
        {
            "eval_loss": 1.6698546409606934,
            "eval_runtime": 3.3969,
            "eval_samples_per_second": 83.605,
            "eval_steps_per_second": 10.598,
            "epoch": 5.0,
            "step": 180
        },
        {
            "train_runtime": 1202.6438,
            "train_samples_per_second": 4.719,
            "train_steps_per_second": 0.15,
            "total_flos": 5123172252131328.0,
            "train_loss": 1.1840438657336765,
            "epoch": 5.0,
            "step": 180
        },
        {
            "eval_loss": 1.6613813638687134,
            "eval_runtime": 3.39,
            "eval_samples_per_second": 83.775,
            "eval_steps_per_second": 10.619,
            "epoch": 5.0,
            "step": 180
        }
    ],
    "perplexity": 5.2665808865524575
}